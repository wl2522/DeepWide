{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T08:30:06.827077Z",
     "start_time": "2017-11-21T08:30:00.586530Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T08:30:41.256601Z",
     "start_time": "2017-11-21T08:30:07.827727Z"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/arraysetops.py:463: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('tmp/train.csv',index_col = 0)\n",
    "test = pd.read_csv('tmp/test.csv',index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-19T06:05:41.816928Z",
     "start_time": "2017-11-19T06:05:41.813924Z"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_set = train\n",
    "split_ratio = 0.8\n",
    "\n",
    "train_set = train_set.sample(frac=1, random_state=6)\n",
    "val_set = train_set[int(split_ratio*train_set.shape[0]):]\n",
    "train_set = train_set[:int(split_ratio*train_set.shape[0])]\n",
    "\n",
    "y_train = train_set['target']\n",
    "train_set.drop('target', axis=1, inplace=True)\n",
    "\n",
    "y_val = val_set['target']\n",
    "val_set.drop('target', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T08:40:16.463412Z",
     "start_time": "2017-11-21T08:40:14.691359Z"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Designate the target feature name and the features to be used in the dataset\n",
    "\n",
    "FEATURES = list(test.columns)\n",
    "LABEL = 'target'\n",
    "\"\"\"\n",
    "#Use the feature_column module to input each feature column into the model\n",
    "\n",
    "target = tf.feature_column.categorical_column_with_identity(key='target', num_buckets=2)\n",
    "\n",
    "registered = tf.feature_column.categorical_column_with_vocabulary_list(key='registered_via',\n",
    "                                                                       vocabulary_list=['7', '4', '9', '3', '13', '16'],\n",
    "                                                                       dtype=tf.string,\n",
    "                                                                       default_value=-99)\n",
    "\n",
    "gender = tf.feature_column.categorical_column_with_vocabulary_list(key='gender',\n",
    "                                                                   vocabulary_list=('female', 'male', 'unknown'),\n",
    "                                                                   dtype=tf.string,\n",
    "                                                                   default_value=-99)\n",
    "\n",
    "city = tf.feature_column.categorical_column_with_vocabulary_list(key='city',\n",
    "                                                          vocabulary_list=members['city'].unique(),\n",
    "                                                          dtype=tf.string,\n",
    "                                                          default_value=-99)\n",
    "\n",
    "language = tf.feature_column.categorical_column_with_vocabulary_list(key='language',\n",
    "                                                                     vocabulary_list=songs['language'].unique(),\n",
    "                                                                     dtype=tf.string,\n",
    "                                                                     default_value=-99)\n",
    "\n",
    "artist = tf.feature_column.categorical_column_with_vocabulary_list(key='artist_name',\n",
    "                                                                   vocabulary_list=songs['artist_name'].unique(),\n",
    "                                                                   dtype=tf.string,\n",
    "                                                                   default_value=-99)\n",
    "\n",
    "tab = tf.feature_column.categorical_column_with_vocabulary_list(key='source_system_tab',\n",
    "                                                                vocabulary_list=train['source_system_tab'].unique(),\n",
    "                                                                dtype=tf.string,\n",
    "                                                                default_value=-99)\n",
    "\n",
    "screen = tf.feature_column.categorical_column_with_vocabulary_list(key='source_screen_name',\n",
    "                                                                   vocabulary_list=train['source_screen_name'].unique(),\n",
    "                                                                   dtype=tf.string,\n",
    "                                                                   default_value=-99)\n",
    "\n",
    "source = tf.feature_column.categorical_column_with_vocabulary_list(key='source_type',\n",
    "                                                                   vocabulary_list=train['source_type'].unique(),\n",
    "                                                                   dtype=tf.string,\n",
    "                                                                   default_value=-99)\n",
    "\n",
    "length = tf.feature_column.numeric_column(key='song_length',\n",
    "                                          default_value=-1,\n",
    "                                          dtype=tf.int32)\n",
    "\n",
    "#Bucket categorical features with many unique categories using a hash table with a size of approximately (n/0.8)*2\n",
    "\n",
    "msno = tf.feature_column.categorical_column_with_hash_bucket(key='msno',\n",
    "                                                               hash_bucket_size=90000,\n",
    "                                                               dtype=tf.string)\n",
    "\n",
    "song_id = tf.feature_column.categorical_column_with_hash_bucket(key='song_id',\n",
    "                                                             hash_bucket_size=6000000,\n",
    "                                                             dtype=tf.string)\n",
    "\n",
    "genre = tf.feature_column.categorical_column_with_vocabulary_list(key='genre_ids',\n",
    "                                                                  vocabulary_list=genres['genre_0'].unique(),\n",
    "                                                                  dtype=tf.string,\n",
    "                                                                  default_value=-99)\n",
    "\n",
    "hashed_genre = tf.feature_column.categorical_column_with_hash_bucket(key='genre_ids',\n",
    "                                                                     hash_bucket_size=3000,\n",
    "                                                                     dtype=tf.string)\n",
    "\n",
    "#Perform one hot encoding on categorical features with few unique values\n",
    "\n",
    "indicator_registered = tf.feature_column.indicator_column(registered)\n",
    "indicator_gender = tf.feature_column.indicator_column(gender)\n",
    "indicator_city = tf.feature_column.indicator_column(city)\n",
    "indicator_genre = tf.feature_column.indicator_column(genre)\n",
    "indicator_language = tf.feature_column.indicator_column(language)\n",
    "indicator_tab = tf.feature_column.indicator_column(tab)\n",
    "indicator_screen = tf.feature_column.indicator_column(screen)\n",
    "indicator_source = tf.feature_column.indicator_column(source)\n",
    "\n",
    "#Embed the categorical feature with <100 unique categories into dense vectors with approximately log2(n) dimensions\n",
    "\n",
    "embedded_genre = tf.feature_column.embedding_column(genre, dimension=10)\n",
    "embedded_song = tf.feature_column.embedding_column(song_id, dimension=22)\n",
    "embedded_msno = tf.feature_column.embedding_column(msno, dimension=15)\n",
    "embedded_artist = tf.feature_column.embedding_column(artist, dimension=18)\n",
    "\n",
    "#Bucket member age into age ranges, with nonsensical values going into the 0-14 or the >80 buckets\n",
    "\n",
    "age = tf.feature_column.numeric_column(key='bd',\n",
    "                                       default_value=0,\n",
    "                                       dtype=tf.int32)\n",
    "\n",
    "age_bucket = tf.feature_column.bucketized_column(age, boundaries=[0, 14, 20, 30, 40, 50, 80])\n",
    "\n",
    "#Assign features to be used in either the wide or the deep model (or both)\n",
    "\"\"\"\n",
    "wide_columns =  [tf.feature_column.numeric_column(key= 'x',\n",
    "                                       shape=(60*2**5,),\n",
    "                                       default_value=0,\n",
    "                                       dtype=tf.int32)]\n",
    "cross_columns = []\n",
    "\"\"\"deep_columns = [\n",
    "                indicator_gender, indicator_city, indicator_language, indicator_tab,\n",
    "                indicator_screen, indicator_source, indicator_registered,\n",
    "                #embedded_msno, embedded_song, embedded_artist, embedded_genre,\n",
    "                #length, age_bucket\n",
    "                ]\"\"\"\n",
    "deep_columns = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T08:40:16.480768Z",
     "start_time": "2017-11-21T08:40:16.463412Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def build_estimator(model_dir, model_type):\n",
    "    if model_type == 'wide':\n",
    "        model = tf.estimator.LinearClassifier(model_dir=model_dir,\n",
    "                                              feature_columns=wide_columns + cross_columns)\n",
    "\n",
    "    elif model_type == 'deep':\n",
    "        model = tf.estimator.DNNClassifier(model_dir=model_dir,\n",
    "                                           feature_columns=deep_columns,\n",
    "                                           hidden_units=[1024, 512, 256],\n",
    "                                           optimizer=tf.train.AdamOptimizer(learning_rate=0.001,\n",
    "                                                                            name='Adam'))\n",
    "\n",
    "    elif model_type == 'combined':\n",
    "        model = tf.estimator.DNNLinearCombinedClassifier(model_dir=model_dir,\n",
    "                                                         linear_feature_columns=cross_columns,\n",
    "                                                         dnn_feature_columns=deep_columns,\n",
    "                                                         dnn_hidden_units=[100, 50])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "feature_trans = joblib.load('./tmp/lgb.pkl')\n",
    "tr_features = feature_trans.predict(train_set.values,pred_leaf=True)\n",
    "va_features = feature_trans.predict(val_set.values,pred_leaf=True)\n",
    "tes_features = feature_trans.predict(test.values,pred_leaf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.data import Dataset\n",
    "from sklearn.externals import joblib\n",
    "feature_trans = joblib.load('./tmp/lgb.pkl')\n",
    "def train_input_fn():\n",
    "    \n",
    "    data = tf.contrib.data.Dataset.from_tensor_slices((train_set.values, y_train.values))\n",
    "    data.repeat(10)\n",
    "    #print('data',data)\n",
    "    #data = data.map(input_parser)\n",
    "    \n",
    "    \"\"\"\n",
    "    data = data.map(\n",
    "    lambda train_set, y_train: tuple(tf.py_func(\n",
    "        _read_py_function, [train_set, y_train], [tf.float32, tf.float32])))\"\"\"\n",
    "\n",
    "    data = data.batch(100)\n",
    "    iterator = data.make_one_shot_iterator()\n",
    "    feature,y = iterator.get_next()\n",
    "    #print('one_shot',one_shot)\n",
    "    \n",
    "    print (feature,y)\n",
    "    return {'x':feature}, y\n",
    "def valid_input_fn():\n",
    "    \n",
    "    data = tf.contrib.data.Dataset.from_generator((train_set.values, y_train.values))\n",
    "    data.repeat(10)\n",
    "    #print('data',data)\n",
    "    #data = data.map(input_parser)\n",
    "    \n",
    "    \"\"\"\n",
    "    data = data.map(\n",
    "    lambda train_set, y_train: tuple(tf.py_func(\n",
    "        _read_py_function, [train_set, y_train], [tf.float32, tf.float32])))\"\"\"\n",
    "\n",
    "    data = data.batch(100)\n",
    "    iterator = data.make_one_shot_iterator()\n",
    "    feature,y = iterator.get_next()\n",
    "    #print('one_shot',one_shot)\n",
    "    \n",
    "    \n",
    "    return {'x':feature}, y\n",
    "\n",
    "\n",
    "def make_generator(X, Y):\n",
    "\n",
    "    def _generator():\n",
    "        for x, y in zip(X, Y):\n",
    "            yield x, y\n",
    "\n",
    "    return _generator\n",
    "def train_input_fn():\n",
    "  \n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "          make_generator(tr_features, y_train.values),\n",
    "          (tf.uint8, tf.float32))\n",
    "    dataset.repeat(None)\n",
    "    \"\"\"dataset = dataset.map(\n",
    "    lambda x, y: tuple(tf.py_func(\n",
    "        _read_py_function, [x, y], [tf.float32, tf.float32])))\"\"\"\n",
    "    dataset = dataset.map(\n",
    "        lambda x, y: tuple((tf.reshape(tf.one_hot(x,depth=2**5),(1920,)),y))\n",
    "    )\n",
    "    batched_dataset = dataset.batch(100)\n",
    "    iterator = batched_dataset.make_one_shot_iterator()\n",
    "    \n",
    "    x, y = list(iterator.get_next())\n",
    "    #print(x,y)\n",
    "    return {'x': x}, tf.expand_dims(y,axis=1)\n",
    "def valid_input_fn():\n",
    "  \n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "          make_generator(va_features, y_val.values),\n",
    "          (tf.uint8, tf.float32))\n",
    "    dataset.repeat(None)\n",
    "    \"\"\"dataset = dataset.map(\n",
    "    lambda x, y: tuple(tf.py_func(\n",
    "        _read_py_function, [x, y], [tf.float32, tf.float32])))\"\"\"\n",
    "    dataset = dataset.map(\n",
    "        lambda x, y: tuple((tf.reshape(tf.one_hot(x,depth=2**5),(1920,)),y))\n",
    "    )\n",
    "    batched_dataset = dataset.batch(100)\n",
    "    iterator = batched_dataset.make_one_shot_iterator()\n",
    "    \n",
    "    x, y = list(iterator.get_next())\n",
    "    #print(x,y)\n",
    "    return {'x': x}, tf.expand_dims(y,axis=1)\n",
    "def predict_generator(X):\n",
    "\n",
    "    def _generator():\n",
    "        for x in X:\n",
    "            yield x\n",
    "\n",
    "    return _generator\n",
    "def predict_input_fn():\n",
    "      \n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "          predict_generator(tes_features),\n",
    "          (tf.uint8))\n",
    "    dataset.repeat(1)\n",
    "    \"\"\"dataset = dataset.map(\n",
    "    lambda x, y: tuple(tf.py_func(\n",
    "        _read_py_function, [x, y], [tf.float32, tf.float32])))\"\"\"\n",
    "    dataset = dataset.map(\n",
    "        lambda x: tf.reshape(tf.one_hot(x,depth=2**5),(1920,))\n",
    "    )\n",
    "    batched_dataset = dataset.batch(10000)\n",
    "    iterator = batched_dataset.make_one_shot_iterator()\n",
    "    \n",
    "    x = iterator.get_next()\n",
    "    #print(x,y)\n",
    "    return {'x': x}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T08:40:16.502790Z",
     "start_time": "2017-11-21T08:40:16.481769Z"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def input_fn(X, y, mode, batch_size):\n",
    "    print(X.shape)\n",
    "    X.fillna(value='unknown', axis=1, inplace=True)    \n",
    "\n",
    "    if mode == 'train':\n",
    "        return train_input_fn\n",
    "    \n",
    "    elif mode == 'eval':\n",
    "        return valid_input_fn \n",
    "        \"\"\"pandas_input_fn(x = pd.DataFrame({k: X[k].values for k in FEATURES}),\n",
    "                                                   y = pd.Series(y.values),\n",
    "                                                   batch_size=batch_size,\n",
    "                                                   num_epochs=1,\n",
    "                                                   shuffle=False,\n",
    "                                                   num_threads=1,\n",
    "                                                   target_column='target')\"\"\"\n",
    "    \n",
    "    elif mode == 'predict':\n",
    "        return predict_input_fn\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T08:40:16.527813Z",
     "start_time": "2017-11-21T08:40:16.503791Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model_dir, model_type, train_steps, X_train, y_train, X_test, y_test, batch_size):\n",
    "\n",
    "#Create a temporary directory to store the model if no model directory argument is given\n",
    "\n",
    "    model_dir = tempfile.mkdtemp() if not model_dir else model_dir\n",
    "    \n",
    "    print('build_estimator')\n",
    "    model = build_estimator(model_dir, model_type)\n",
    "    \n",
    "    print('train start')\n",
    "    model.train(input_fn=input_fn(X_train, y_train, mode='train', batch_size=batch_size),\n",
    "                max_steps=train_steps)\n",
    "    \n",
    "#Evaluate the trained model on a separate validation set in n/batch_size steps\n",
    "    print('eval start')\n",
    "    model.evaluate(input_fn=input_fn(X_test, y_test, mode='eval', batch_size=batch_size),\n",
    "                        steps=100)\n",
    "\n",
    "    print('end!')\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T09:56:10.044495Z",
     "start_time": "2017-11-21T08:40:16.528814Z"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build_estimator\n",
      "INFO:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_task_type': 'worker', '_service': None, '_master': '', '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_keep_checkpoint_every_n_hours': 10000, '_task_id': 0, '_save_summary_steps': 100, '_keep_checkpoint_max': 5, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe3217afef0>, '_num_ps_replicas': 0, '_model_dir': 'model/', '_session_config': None, '_num_worker_replicas': 1, '_tf_random_seed': None, '_is_chief': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_task_type': 'worker', '_service': None, '_master': '', '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_keep_checkpoint_every_n_hours': 10000, '_task_id': 0, '_save_summary_steps': 100, '_keep_checkpoint_max': 5, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe3217afef0>, '_num_ps_replicas': 0, '_model_dir': 'model/', '_session_config': None, '_num_worker_replicas': 1, '_tf_random_seed': None, '_is_chief': True}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train start\n",
      "(5901934, 16)\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval start\n",
      "(1475484, 16)\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2017-11-25-23:33:05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2017-11-25-23:33:05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [1/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [1/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [2/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [2/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [3/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [3/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [4/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [4/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [5/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [5/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [6/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [6/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [7/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [7/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [8/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [8/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [9/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [9/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [10/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [10/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [11/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [11/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [12/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [12/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [13/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [13/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [14/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [14/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [15/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [15/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [16/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [16/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [17/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [17/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [18/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [18/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [19/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [19/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [20/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [20/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [21/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [21/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [22/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [22/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [23/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [23/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [24/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [24/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [25/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [25/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [26/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [26/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [27/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [27/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [28/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [28/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [29/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [29/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [30/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [30/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [31/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [31/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [32/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [32/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [33/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [33/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [34/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [34/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [35/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [35/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [36/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [36/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [37/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [37/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [38/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [38/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [39/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [39/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [40/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [40/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [41/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [41/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [42/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [42/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [43/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [43/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [44/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [44/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [45/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [45/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [46/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [46/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [47/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [47/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [48/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [48/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [49/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [49/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [50/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [50/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [51/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [51/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [52/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [52/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [53/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [53/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [54/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [54/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [55/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [55/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [56/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [56/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [57/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [57/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [58/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [58/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [59/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [59/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [60/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [60/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [61/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [61/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [62/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [62/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [63/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [63/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [64/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [64/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [65/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [65/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [66/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [66/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [67/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [67/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [68/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [68/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [69/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [69/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [70/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [70/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [71/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [71/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [72/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [72/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [73/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [73/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [74/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [74/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [75/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [75/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [76/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [76/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [77/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [77/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [78/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [78/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [79/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [79/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [80/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [80/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [81/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [81/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [82/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [82/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [83/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [83/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [84/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [84/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [85/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [85/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [86/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [86/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [87/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [87/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [88/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [88/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [89/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [89/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [90/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [90/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [91/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [91/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [92/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [92/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [93/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [93/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [94/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [94/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [95/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [95/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [96/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [96/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [97/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [97/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [98/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [98/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [99/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [99/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [100/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [100/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2017-11-25-23:33:11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2017-11-25-23:33:11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.6479, accuracy_baseline = 0.5035, auc = 0.703863, auc_precision_recall = 0.691687, average_loss = 0.625786, global_step = 1000, label/mean = 0.5035, loss = 62.5786, prediction/mean = 0.52444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.6479, accuracy_baseline = 0.5035, auc = 0.703863, auc_precision_recall = 0.691687, average_loss = 0.625786, global_step = 1000, label/mean = 0.5035, loss = 62.5786, prediction/mean = 0.52444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end!\n"
     ]
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "wide_model = train_model(model_dir='model/', model_type='wide', train_steps=1000,\n",
    "                         X_train=train_set, y_train=y_train,\n",
    "                         X_test=val_set, y_test=y_val,\n",
    "                         batch_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T09:56:52.357829Z",
     "start_time": "2017-11-21T09:56:10.046496Z"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"results = wide_model.evaluate(input_fn=input_fn(train_set, y_train, mode='eval', batch_size=1000),\\n                              steps=1476)\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"results = wide_model.evaluate(input_fn=input_fn(train_set, y_train, mode='eval', batch_size=1000),\n",
    "                              steps=1476)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T09:57:38.223184Z",
     "start_time": "2017-11-21T09:56:52.360701Z"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print' (<ipython-input-30-c73e303e47fe>, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-30-c73e303e47fe>\"\u001b[0;36m, line \u001b[0;32m10\u001b[0m\n\u001b[0;31m    print i\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'\n"
     ]
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "predictions = wide_model.predict(input_fn=input_fn(test, None, mode='predict',\n",
    "                                                   batch_size=10000))\n",
    "count = 0\n",
    "submission = list()\n",
    "\n",
    "for row in predictions:\n",
    "    submission.append(row['probabilities'][1])\n",
    "    count += 1\n",
    "    if(count % 10 == 0):\n",
    "        print(count)\n",
    "    #print(row)\n",
    "pd.DataFrame(data={'id': ids,\n",
    "                   'target': np.array(submission)}).to_csv('submissions/benchmark_deep.csv',\n",
    "                                                           header=['id', 'target'],\n",
    "                                                           index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "730000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2556790, 16)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "notify_time": "30"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
